{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import os\r\n",
    "import time\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "import torch.nn as nn\r\n",
    "from math import sqrt\r\n",
    "import copy\r\n",
    "import h5py\r\n",
    "from collections import deque"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "logging_interval = 40\r\n",
    "logdir = './DDPG'\r\n",
    "base_dir = './channels'\r\n",
    "SEED = 0\r\n",
    "MAX_PATH_LENGTH = 500\r\n",
    "NUM_EPISODES = 1200\r\n",
    "GAMMA = 0.99\r\n",
    "BATCH_SIZE = 128\r\n",
    "UPDATES = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class wirelessEnv:\r\n",
    "    def __init__(self, pu, nrx, gainspath, random_seed):\r\n",
    "        print(pu)\r\n",
    "        random.seed(random_seed)\r\n",
    "        self.filename = base_dir+str(gainspath)\r\n",
    "        self.channelGains = h5py.File(self.filename, 'r')\r\n",
    "        self.B = 20000000\r\n",
    "        self.N0 = 1\r\n",
    "\r\n",
    "        self.T_c = 0.001\r\n",
    "        \r\n",
    "        self.Ptcm = 0.2\r\n",
    "        self.Ptcl = 0.2\r\n",
    "        self.Pom = 0.825\r\n",
    "        self.pp = 0.2\r\n",
    "        \r\n",
    "        self.K = 10\r\n",
    "        self.tauc = 200\r\n",
    "        self.eff = 0.4 #amplifier efficiency\r\n",
    "        self.M = 32\r\n",
    "        self.pu = pu\r\n",
    "        #self.ui = 4 # for all i\r\n",
    "        #self.F = 3\r\n",
    "        #self.Pfix =  # for all i\r\n",
    "        self.Pft = 10\r\n",
    "        self.C_fh = 100000000\r\n",
    "        self.nu = 2\r\n",
    "        self.a = 0.88115\r\n",
    "        self.b = 0.88115\r\n",
    "        self.taup = self.K\r\n",
    "        self.tauf = 1 - (self.taup/self.tauc)\r\n",
    "        #print(self.tauf)\r\n",
    "        self.Nrx = nrx\r\n",
    "        \r\n",
    "        self.R_fh = 2*self.K*self.nu*self.tauf*self.tauc/self.T_c\r\n",
    "        #print(self.R_fh)\r\n",
    "        self.Pfix   = self.M*((self.Nrx*self.Ptcm)+self.Pom + self.Pft*self.R_fh/self.C_fh)/self.K\r\n",
    "        #print(self.Pfix)\r\n",
    "        self.theta_max = 1\r\n",
    "        #self.sigma2 = self.F*self.N0*self.B\r\n",
    "        self.alpha = deque(maxlen=1)\r\n",
    "        self.beta = deque(maxlen=1)\r\n",
    "        self.ch_gain = deque(maxlen=1)\r\n",
    "        self.wi = [1/self.K for i in range(self.K)] # define equal weights which sum to 1\r\n",
    "        self.pi = deque(maxlen=1)\r\n",
    "        self.initialize_p()\r\n",
    "        self.a_dim = self.K\r\n",
    "        self.action_bound = np.asarray([0, 1])\r\n",
    "        # initialize actions\r\n",
    "        #self.actions = [0.00001]  \r\n",
    "        #for x in range(self.action_space-1):\r\n",
    "            #self.actions.append((x+1)*self.theta_max/(self.action_space-1))    \r\n",
    "        # input/output for the neural net\r\n",
    "        #self.s_dim = 8*self.K + 4*self.M + 2\r\n",
    "        self.s_dim = self.K*self.M\r\n",
    "        # self.s_dim = 4*self.M + 3*self.K - 1\r\n",
    "        self.input = 100\r\n",
    "        self.output = self.a_dim\r\n",
    "        \r\n",
    "    def initialize_matrix(self, episode):\r\n",
    "        for t in range(2):\r\n",
    "          # BETA = np.random.rand(self.M, self.K)\r\n",
    "          BETA = self.channelGains['channelGain'][episode].transpose()\r\n",
    "          gamma_num = np.zeros((self.M,self.K))\r\n",
    "          gamma_den = np.zeros((self.M,self.K))\r\n",
    "\r\n",
    "          Gamma = np.zeros((self.M,self.K))\r\n",
    "          for m in range(self.M):\r\n",
    "              for k in range(self.K):\r\n",
    "                  gamma_num[m][k] = self.taup*self.pp*np.power(BETA[m][k],2)                                  \r\n",
    "                  gamma_den[m][k] = self.taup*self.pp*BETA[m][k]+1                    \r\n",
    "                  Gamma[m][k] = gamma_num[m][k]/gamma_den[m][k]\r\n",
    "          self.ch_gain.append(Gamma)\r\n",
    "          alpha1 = np.zeros((self.K,))\r\n",
    "          for k in range(self.K):\r\n",
    "              #alpha1[k] = self.Nrx*self.pu*np.sum(Gamma[:][k])*self.pi[t][k]\r\n",
    "              alpha1[k] = self.pu*np.power(self.a*self.Nrx*np.sum(Gamma[:,k]),2)\r\n",
    "          self.alpha.append(alpha1)\r\n",
    "          beta1 = np.zeros((self.K,self.K))\r\n",
    "          for k in range(self.K):\r\n",
    "              for q in range(self.K):\r\n",
    "                  beta1 [k][q] = self.a*self.a*self.pu*self.Nrx*(BETA[:,q].T@Gamma[:,k])         \r\n",
    "          self.beta.append(beta1)\r\n",
    "          # if episode >= 1999:\r\n",
    "          #   print(f'Gamma:{Gamma}')\r\n",
    "          #self.alpha_beta.append(np.array([[np.random.uniform(0,1) for e in range(K)] for e in range(K)]))        \r\n",
    "        return\r\n",
    "\r\n",
    "    def initialize_p(self):\r\n",
    "        self.pi.append(np.random.uniform(low=0, high=self.theta_max, size=(self.K,)))\r\n",
    "        return\r\n",
    "    \r\n",
    "    def cal_alpha_p(self, i, t):\r\n",
    "        val = self.alpha[t][i]*self.pi[t][i]\r\n",
    "        # print(f'cal_alpha_p: {val}')\r\n",
    "        return val\r\n",
    "    \r\n",
    "    def cal_beta_p(self, i, j, t):\r\n",
    "        val = self.beta[t][i][j]*self.pi[t][j] # channel from UE j to BS i\r\n",
    "        # print(f'cal_beta_p: {val}')\r\n",
    "        return val\r\n",
    "    \r\n",
    "    def sum_beta_p(self, i, t):\r\n",
    "        val = 0\r\n",
    "        for j in range(self.K):\r\n",
    "            val += self.cal_beta_p(i,j,t)  \r\n",
    "        #val = val + (self.b-self.a*self.a)*self.Nrx*self.pu*np.sum(np.square(np.asarray(self.ch_gain)[t,:,i]))/(np.asarray(self.ch_gain)[t,:,i]))\r\n",
    "        # print(f'sum_beta_p: {val}')\r\n",
    "        return val \r\n",
    "\r\n",
    "    def cal_Ri(self,i, t):\r\n",
    "        val = np.log2(1+(self.cal_alpha_p(i,t)/(self.b*self.Nrx*np.sum(np.asarray(self.ch_gain)[t,:,i]) + (self.b-self.a*self.a)*self.Nrx*self.Nrx*self.pu*self.pi[t][i]*np.linalg.norm(np.asarray(self.ch_gain)[t,:,i])**2 + self.b/(self.a*self.a)*self.sum_beta_p(i, t))))\r\n",
    "        return val\r\n",
    "        \r\n",
    "    def cal_equal_p_Ri(self,i, t):\r\n",
    "        p = [self.theta_max for x in range(self.K)]\r\n",
    "        temp = self.pi.copy()\r\n",
    "        self.pi[t] = p\r\n",
    "        val = self.cal_Ri(i,t)\r\n",
    "        self.pi = temp\r\n",
    "        return val\r\n",
    "\r\n",
    "    def cal_EEi(self,i,t):\r\n",
    "        val = self.tauf*self.cal_Ri(i,t)/(self.pu*self.N0*self.pi[t][i]/self.eff + self.Pfix + self.Ptcl)\r\n",
    "        return val\r\n",
    "\r\n",
    "    def cal_total_WSEE(self,t):\r\n",
    "        val = 0\r\n",
    "        for x in range(self.K):\r\n",
    "            val += self.wi[x]*self.cal_EEi(x,t)\r\n",
    "        return val\r\n",
    "    \r\n",
    "    def cal_equal_p_WSEE(self, t):\r\n",
    "        p = [self.theta_max for x in range(self.K)]\r\n",
    "        temp = self.pi.copy()\r\n",
    "        self.pi[t] = p\r\n",
    "        val = self.cal_total_WSEE(t)\r\n",
    "        self.pi = temp\r\n",
    "        return val\r\n",
    "  \r\n",
    "    def cal_SE_vec(self,t):\r\n",
    "        SEs = []\r\n",
    "        for u in range(self.K):\r\n",
    "          SE_u = self.tauf*self.cal_Ri(u,t)\r\n",
    "          SEs.append(SE_u)\r\n",
    "        return SEs\r\n",
    "\r\n",
    "    def cal_sum_SE(self,t):\r\n",
    "        SEs = self.cal_SE_vec(t)\r\n",
    "        sum_SE = sum([se for se in SEs])\r\n",
    "        return sum_SE\r\n",
    "\r\n",
    "    def cal_fpa_SE_vec(self,t):\r\n",
    "        SEs = []\r\n",
    "        for u in range(self.K):\r\n",
    "          SE_u = self.tauf*self.cal_equal_p_Ri(u,t)\r\n",
    "          SEs.append(SE_u)\r\n",
    "        return SEs\r\n",
    "\r\n",
    "    def cal_sum_fpa_SE(self,t):\r\n",
    "        SEs = self.cal_fpa_SE_vec(t)\r\n",
    "        sum_SE = sum([se for se in SEs])\r\n",
    "        return sum_SE\r\n",
    "\r\n",
    "    def cal_reward(self,t):\r\n",
    "        #ri = self.wi[i]*self.cal_EEi(i,t) - self.sum_price(i,t)\r\n",
    "        # ri = self.cal_total_WSEE(t)\r\n",
    "        # ri = (np.log(self.cal_total_WSEE(t)) - np.log(self.cal_equal_p_WSEE(t)))\r\n",
    "        # ri = self.cal_total_WSEE(t) - self.cal_equal_p_WSEE(t) \r\n",
    "        \r\n",
    "        \r\n",
    "        #Uncomment for only WSEE\r\n",
    "        # ri = (self.cal_total_WSEE(t) - self.cal_equal_p_WSEE(t)) \r\n",
    "        # return ri\r\n",
    "\r\n",
    "\r\n",
    "        # Uncomment for sum_SE+WSEE\r\n",
    "        sum_se_reward = 0;        \r\n",
    "        for u in range(self.K):\r\n",
    "          sum_se_reward += self.tauf*(self.cal_Ri(u,t) - self.cal_equal_p_Ri(u,t))\r\n",
    "                \r\n",
    "        ri = (self.cal_total_WSEE(t) - self.cal_equal_p_WSEE(t)) \r\n",
    "        \r\n",
    "        return 1.5*sum_se_reward + 0.5*ri\r\n",
    "\r\n",
    "  \r\n",
    "    def cal_state(self):\r\n",
    "        state = []\r\n",
    "        indx = 0\r\n",
    "        for t in reversed(range(1)): #for current timestep only\r\n",
    "          for m in range(self.M):\r\n",
    "            for k in range(self.K):\r\n",
    "              state.append(self.ch_gain[t][m][k]) #M\r\n",
    "            \r\n",
    "        state = np.reshape(state, [1, self.s_dim])\r\n",
    "        return np.asarray(-np.log10(state))\r\n",
    "\r\n",
    "    def initialize_state(self):\r\n",
    "        # UE = random.randint(0,self.K-1)\r\n",
    "        state = self.cal_state()\r\n",
    "        return state\r\n",
    "\r\n",
    "    def reset(self, episode):\r\n",
    "        self.initialize_matrix(episode)\r\n",
    "#         self.initialize_p()\r\n",
    "        self.episode_step = 0\r\n",
    "        state = self.initialize_state()\r\n",
    "        return state\r\n",
    "\r\n",
    "    def initialize_state_test(self,):\r\n",
    "        state = self.cal_state()\r\n",
    "        return state\r\n",
    "\r\n",
    "    def reset_test(self, episode):\r\n",
    "        self.initialize_matrix(episode)\r\n",
    "        self.episode_step = 0\r\n",
    "\r\n",
    "    def agent_reset(self):\r\n",
    "        state = self.initialize_state()\r\n",
    "        state = np.reshape(state, [1, self.s_dim])\r\n",
    "        return state\r\n",
    "\r\n",
    "            \r\n",
    "    def step(self, actions):\r\n",
    "        self.episode_step += 1\r\n",
    "        actions = actions[0] #theres an extra dim\r\n",
    "        self.pi.append(actions)\r\n",
    "        next_state = self.cal_state()\r\n",
    "        reward = self.cal_reward(0)\r\n",
    "        next_state = np.reshape(next_state, [1, self.s_dim])\r\n",
    "        done = False\r\n",
    "        if self.episode_step >= UPDATES:\r\n",
    "            done = True\r\n",
    "        return next_state, reward, done"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "power = 50\r\n",
    "pu = np.power(10,power/10 - 3)\r\n",
    "nrx = 2\r\n",
    "gainspath = '/channel_K10_AP32_2k_fresh.h5'\r\n",
    "env = wirelessEnv(pu,nrx,gainspath,SEED)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "obs_dim = env.s_dim\r\n",
    "act_dim = env.a_dim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "torch.manual_seed(SEED)\r\n",
    "np.random.seed(SEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "use_cuda = torch.cuda.is_available()\r\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\r\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\r\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\r\n",
    "Tensor = FloatTensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def weightSync(target_model, source_model, tau=0.001):\r\n",
    "    for parameter_target, parameter_source in zip(target_model.parameters(), source_model.parameters()):\r\n",
    "        parameter_target.data.copy_((1 - tau) * parameter_target.data + tau * parameter_source.data)\r\n",
    "\r\n",
    "\r\n",
    "class OrnsteinUhlenbeckProcess:\r\n",
    "    def __init__(self, mu=np.zeros(act_dim), sigma=0.05, theta=.25, dimension=1e-2, x0=None,num_steps=12000):\r\n",
    "        self.theta = theta\r\n",
    "        self.mu = mu\r\n",
    "        self.sigma = sigma\r\n",
    "        self.dt = dimension\r\n",
    "        self.x0 = x0\r\n",
    "        self.reset()\r\n",
    "\r\n",
    "    def step(self):\r\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\r\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\r\n",
    "        self.x_prev = x\r\n",
    "        return x\r\n",
    "\r\n",
    "    def reset(self):\r\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class AdaptiveParamNoiseSpec(object):\r\n",
    "    def __init__(self, initial_stddev=0.1, desired_action_stddev=0.2, adaptation_coefficient=1.01):\r\n",
    "        \"\"\"\r\n",
    "        Note that initial_stddev and current_stddev refer to std of parameter noise, \r\n",
    "        but desired_action_stddev refers to (as name notes) desired std in action space\r\n",
    "        \"\"\"\r\n",
    "        self.initial_stddev = initial_stddev\r\n",
    "        self.desired_action_stddev = desired_action_stddev\r\n",
    "        self.adaptation_coefficient = adaptation_coefficient\r\n",
    "\r\n",
    "        self.current_stddev = initial_stddev\r\n",
    "\r\n",
    "    def adapt(self, distance):\r\n",
    "        if distance > self.desired_action_stddev:\r\n",
    "            # Decrease stddev.\r\n",
    "            self.current_stddev /= self.adaptation_coefficient\r\n",
    "        else:\r\n",
    "            # Increase stddev.\r\n",
    "            self.current_stddev *= self.adaptation_coefficient\r\n",
    "\r\n",
    "    def get_stats(self):\r\n",
    "        stats = {\r\n",
    "            'param_noise_stddev': self.current_stddev,\r\n",
    "        }\r\n",
    "        return stats\r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        fmt = 'AdaptiveParamNoiseSpec(initial_stddev={}, desired_action_stddev={}, adaptation_coefficient={})'\r\n",
    "        return fmt.format(self.initial_stddev, self.desired_action_stddev, self.adaptation_coefficient)\r\n",
    "\r\n",
    "def ddpg_distance_metric(actions1, actions2):\r\n",
    "    \"\"\"\r\n",
    "    Compute \"distance\" between actions taken by two policies at the same states\r\n",
    "    Expects numpy arrays\r\n",
    "    \"\"\"\r\n",
    "    diff = actions1-actions2\r\n",
    "    mean_diff = np.mean(np.square(diff), axis=0)\r\n",
    "    dist = sqrt(np.mean(mean_diff))\r\n",
    "    return dist\r\n",
    "\r\n",
    "\r\n",
    "def hard_update(target, source):\r\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\r\n",
    "           target_param.data.copy_(param.data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Replay(object):\r\n",
    "    def __init__(self, maxlen=60000):\r\n",
    "        self.maxlen = maxlen\r\n",
    "        self.data = []\r\n",
    "        self.position = 0\r\n",
    "\r\n",
    "    def initialize(self, init_length=1000, envir=env):\r\n",
    "        s = envir.reset()\r\n",
    "        for i in range(init_length):\r\n",
    "            a = env.action_space.sample()\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tensorflow_ddpg': conda)"
  },
  "interpreter": {
   "hash": "ad3b5fcce3603568eab6bc8cfcb8d6ab1dc25917825ed17401970e724080909f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}